{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d1f1b6-2286-4859-9be1-416d213bc4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T07:40:50.335096Z",
     "iopub.status.busy": "2024-12-07T07:40:50.334022Z",
     "iopub.status.idle": "2024-12-07T07:40:50.355241Z",
     "shell.execute_reply": "2024-12-07T07:40:50.354614Z",
     "shell.execute_reply.started": "2024-12-07T07:40:50.335068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pickle\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    \"\"\"\n",
    "    A content-based recommender system based on joke embeddings and features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity_matrix, joke_ids):\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.joke_ids = joke_ids\n",
    "\n",
    "    def recommend(self, joke_id, top_n=10):\n",
    "        \"\"\"\n",
    "        Recommends similar jokes to the given joke ID.\n",
    "\n",
    "        Args:\n",
    "            joke_id (int): ID of the joke to recommend similar jokes for.\n",
    "            top_n (int): Number of similar jokes to return.\n",
    "\n",
    "        Returns:\n",
    "            list: Top-N recommended joke IDs.\n",
    "        \"\"\"\n",
    "        if joke_id not in self.joke_ids:\n",
    "            raise ValueError(f\"Joke ID {joke_id} not found in the dataset.\")\n",
    "        \n",
    "        idx = self.joke_ids.index(joke_id)\n",
    "        similarity_scores = self.similarity_matrix[idx]\n",
    "        top_indices = np.argsort(similarity_scores)[::-1][1:top_n + 1]\n",
    "        return [self.joke_ids[i] for i in top_indices]\n",
    "\n",
    "# Load data\n",
    "train_path = \"../data/processed/train_data.csv\"\n",
    "jokes_path = \"../data/processed/jokes_with_clusters.parquet\"\n",
    "\n",
    "train_df = pl.read_csv(train_path)\n",
    "jokes_df = pl.read_parquet(jokes_path)\n",
    "\n",
    "# Step 1: Merge jokes with features and prepare embeddings\n",
    "jokes_features = jokes_df.select(\n",
    "    [\"jokeId\", \"text_length\", \"word_count\", \"num_ratings\", \"avg_rating\", \"rating_std\", \"embeddings\"]\n",
    ")\n",
    "\n",
    "# Expand embeddings into separate columns for processing\n",
    "embeddings = np.vstack(jokes_features[\"embeddings\"].to_list())\n",
    "jokes_features = jokes_features.drop(\"embeddings\")\n",
    "\n",
    "# Combine features and embeddings\n",
    "combined_features = np.hstack([\n",
    "    jokes_features.drop(\"jokeId\").to_numpy(),\n",
    "    embeddings\n",
    "])\n",
    "\n",
    "# Step 2: Compute cosine similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "\n",
    "# Step 3: Save similarity matrix and joke IDs using pickle\n",
    "joke_ids = jokes_features[\"jokeId\"].to_list()\n",
    "model_path = \"../models/content_based_recommender.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump({\"similarity_matrix\": similarity_matrix, \"joke_ids\": joke_ids}, f)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Step 4: Define function to load and recommend\n",
    "def recommend_from_pickle(joke_id, top_n=10):\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "        similarity_matrix = data[\"similarity_matrix\"]\n",
    "        joke_ids = data[\"joke_ids\"]\n",
    "    \n",
    "    if joke_id not in joke_ids:\n",
    "        raise ValueError(f\"Joke ID {joke_id} not found in the dataset.\")\n",
    "    \n",
    "    idx = joke_ids.index(joke_id)\n",
    "    similarity_scores = similarity_matrix[idx]\n",
    "    top_indices = np.argsort(similarity_scores)[::-1][1:top_n + 1]\n",
    "    return [joke_ids[i] for i in top_indices]\n",
    "\n",
    "# Example usage\n",
    "joke_id = joke_ids[0]  # Replace with a valid jokeId\n",
    "recommendations = recommend_from_pickle(joke_id)\n",
    "print(f\"Recommendations for joke {joke_id}: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "018f0003-848f-4f93-8476-d68d79c1bf64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T07:40:50.761799Z",
     "iopub.status.busy": "2024-12-07T07:40:50.760757Z",
     "iopub.status.idle": "2024-12-07T07:40:50.817887Z",
     "shell.execute_reply": "2024-12-07T07:40:50.817051Z",
     "shell.execute_reply.started": "2024-12-07T07:40:50.761770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class '__main__.ContentBasedRecommender'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5023/3134354466.py\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# ONNX conversion (no direct way to save similarity; wrap in an API-like structure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_joke_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] convert_topology\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     onnx_model = convert_topology(\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1348\u001b[0m                         \u001b[0m_check_variable_out_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Shape2] call infer_types for %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_graph_status_for_traversing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36minfer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# Invoke a core inference function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             raise MissingShapeCalculator(\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \"Unable to find a shape calculator for type '{}'.\".format(\n\u001b[1;32m    633\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class '__main__.ContentBasedRecommender'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    \"\"\"\n",
    "    A content-based recommender system based on joke embeddings and features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity_matrix, joke_ids):\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.joke_ids = joke_ids\n",
    "\n",
    "    def recommend(self, joke_id, top_n=10):\n",
    "        \"\"\"\n",
    "        Recommends similar jokes to the given joke ID.\n",
    "\n",
    "        Args:\n",
    "            joke_id (int): ID of the joke to recommend similar jokes for.\n",
    "            top_n (int): Number of similar jokes to return.\n",
    "\n",
    "        Returns:\n",
    "            list: Top-N recommended joke IDs.\n",
    "        \"\"\"\n",
    "        if joke_id not in self.joke_ids:\n",
    "            raise ValueError(f\"Joke ID {joke_id} not found in the dataset.\")\n",
    "        \n",
    "        idx = self.joke_ids.index(joke_id)\n",
    "        similarity_scores = self.similarity_matrix[idx]\n",
    "        top_indices = np.argsort(similarity_scores)[::-1][1:top_n + 1]\n",
    "        return [self.joke_ids[i] for i in top_indices]\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_path = \"../data/processed/train_data.csv\"\n",
    "jokes_path = \"../data/processed/jokes_with_clusters.parquet\"\n",
    "\n",
    "train_df = pl.read_csv(train_path)\n",
    "jokes_df = pl.read_parquet(jokes_path)\n",
    "\n",
    "# Step 1: Merge jokes with features and prepare embeddings\n",
    "jokes_features = jokes_df.select(\n",
    "    [\"jokeId\", \"text_length\", \"word_count\", \"num_ratings\", \"avg_rating\", \"rating_std\", \"embeddings\"]\n",
    ")\n",
    "\n",
    "# Expand embeddings into separate columns for processing\n",
    "embeddings = np.vstack(jokes_features[\"embeddings\"].to_list())\n",
    "jokes_features = jokes_features.drop(\"embeddings\")\n",
    "\n",
    "# Combine features and embeddings\n",
    "combined_features = np.hstack([\n",
    "    jokes_features.drop(\"jokeId\").to_numpy(),\n",
    "    embeddings\n",
    "])\n",
    "\n",
    "# Step 2: Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "\n",
    "# Step 3: Save similarity matrix and recommender model in ONNX format\n",
    "joke_ids = jokes_features[\"jokeId\"].to_list()\n",
    "recommender = ContentBasedRecommender(similarity_matrix, joke_ids)\n",
    "\n",
    "# Save similarity matrix and joke IDs in ONNX\n",
    "onnx_path = \"../models/content_based_recommender.onnx\"\n",
    "\n",
    "# ONNX conversion (no direct way to save similarity; wrap in an API-like structure)\n",
    "input_type = [('input_joke_index', FloatTensorType([None, 1]))]\n",
    "onnx_model = convert_sklearn(recommender, initial_types=input_type)\n",
    "onnx.save_model(onnx_model, onnx_path)\n",
    "\n",
    "print(f\"Content-Based Recommender saved as ONNX at {onnx_path}\")\n",
    "\n",
    "# Step 4: Usage example\n",
    "# Loading and recommending\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "def recommend_from_onnx(joke_id, top_n=10):\n",
    "    joke_index = joke_ids.index(joke_id)\n",
    "    input_feed = {'input_joke_index': np.array([[joke_index]], dtype=np.float32)}\n",
    "    output = ort_session.run(None, input_feed)[0]\n",
    "    top_indices = np.argsort(output)[::-1][1:top_n + 1]\n",
    "    return [joke_ids[i] for i in top_indices]\n",
    "\n",
    "# Example usage:\n",
    "joke_id = joke_ids[0]  # Replace with a valid jokeId\n",
    "recommendations = recommend_from_onnx(joke_id)\n",
    "print(f\"Recommendations for joke {joke_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afcf4d-3d3a-4adf-a946-3f80ce781d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
