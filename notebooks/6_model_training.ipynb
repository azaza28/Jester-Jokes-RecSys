{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a592de-b12c-4a65-a9c0-7410d52d3da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:18.515418Z",
     "iopub.status.busy": "2024-12-07T13:02:18.515092Z",
     "iopub.status.idle": "2024-12-07T13:02:27.420373Z",
     "shell.execute_reply": "2024-12-07T13:02:27.419599Z",
     "shell.execute_reply.started": "2024-12-07T13:02:18.515395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..')) \n",
    "sys.path.append(project_root)\n",
    "\n",
    "from models.baseline_model import BaselineModel\n",
    "from models.content_based_model import ContentBasedModel\n",
    "from models.collaborative_memory_model import CollaborativeMemoryModel\n",
    "from models.collaborative_model_based import CollaborativeModelBased\n",
    "from models.session_based_model import SessionBasedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7db87f-562a-4246-8200-2256f3c92157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.422030Z",
     "iopub.status.busy": "2024-12-07T13:02:27.421605Z",
     "iopub.status.idle": "2024-12-07T13:02:27.433950Z",
     "shell.execute_reply": "2024-12-07T13:02:27.433295Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.422011Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(train_path=\"../data/processed/train_data.csv\", jokes_path=\"../data/processed/jokes_with_clusters.parquet\"):\n",
    "    \"\"\"\n",
    "    Load training data and joke metadata.\n",
    "\n",
    "    Args:\n",
    "        train_path (str): Path to training data.\n",
    "        jokes_path (str): Path to joke metadata with clusters.\n",
    "\n",
    "    Returns:\n",
    "        train_df (pl.DataFrame): Training set.\n",
    "        jokes_df (pl.DataFrame): Jokes metadata.\n",
    "    \"\"\"\n",
    "    print(f\"üìÇ Loading training data from {train_path}...\")\n",
    "    train_df = pl.read_csv(train_path)\n",
    "    print(f\"‚úÖ Training data loaded successfully! Shape: {train_df.shape}\")\n",
    "    \n",
    "    print(f\"üìÇ Loading joke data from {jokes_path}...\")\n",
    "    jokes_df = pl.read_parquet(jokes_path)\n",
    "    print(f\"‚úÖ Joke data loaded successfully! Shape: {jokes_df.shape}\")\n",
    "    \n",
    "    return train_df, jokes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc226fe0-2bc2-482a-87cb-bbe5aff9f522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.434955Z",
     "iopub.status.busy": "2024-12-07T13:02:27.434672Z",
     "iopub.status.idle": "2024-12-07T13:02:27.446565Z",
     "shell.execute_reply": "2024-12-07T13:02:27.445977Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.434938Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_baseline(train_df: pl.DataFrame, items_df: pl.DataFrame, save_path: str = \"../models/baseline_model.parquet\"):\n",
    "    \"\"\"\n",
    "    Trains the BaselineModel and saves it as a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        train_df (pl.DataFrame): The training data containing 'userId', 'jokeId', 'rating', and other columns.\n",
    "        items_df (pl.DataFrame): The joke metadata containing at least the 'jokeId' column.\n",
    "        save_path (str): The path where the trained model should be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Training Baseline Model...\")\n",
    "\n",
    "    baseline_model = BaselineModel(ratings=train_df, items=items_df)\n",
    "    baseline_model.train()\n",
    "    print(\"‚úÖ Baseline Model training completed!\")\n",
    "\n",
    "    baseline_model.save_model(save_path)\n",
    "    print(f\"üíæ Baseline Model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90711d9-7b07-4482-bd7a-8d41ba0bd5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.448099Z",
     "iopub.status.busy": "2024-12-07T13:02:27.447786Z",
     "iopub.status.idle": "2024-12-07T13:02:27.459649Z",
     "shell.execute_reply": "2024-12-07T13:02:27.459039Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.448082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_content_based(jokes_df: pl.DataFrame, save_path: str = \"../models/content_based/\"):\n",
    "    \"\"\"\n",
    "    üöÄ Trains the Content-Based Model and saves the similarity matrix and joke IDs.\n",
    "\n",
    "    Args:\n",
    "        jokes_df (pl.DataFrame): The joke features DataFrame, containing 'jokeId', 'embeddings', and other features.\n",
    "        save_path (str): The directory where the trained model files will be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Content-Based Model...\")\n",
    "\n",
    "    # Ensure 'embeddings' column exists\n",
    "    if 'embeddings' not in jokes_df.columns:\n",
    "        raise ValueError(\"‚ùå The DataFrame must contain an 'embeddings' column with precomputed joke embeddings.\")\n",
    "\n",
    "    # Extract joke IDs and embeddings from the DataFrame\n",
    "    joke_ids = jokes_df[\"jokeId\"].to_list()\n",
    "    embeddings = np.vstack(jokes_df[\"embeddings\"].to_list())\n",
    "\n",
    "    print(f\"üì¶ Loaded {len(joke_ids)} jokes and their embeddings of shape {embeddings.shape}.\")\n",
    "\n",
    "    # Step 1: Train the Content-Based Recommender Model\n",
    "    print(\"üöÄ Training Content-Based Recommender...\")\n",
    "    content_model = ContentBasedModel()\n",
    "    content_model.train(embeddings, joke_ids)\n",
    "    print(f\"‚úÖ Content-Based model trained successfully.\")\n",
    "\n",
    "    # Step 2: Save the trained model\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    print(f\"üíæ Saving Content-Based model to {save_path}...\")\n",
    "    content_model.save_model(save_path)\n",
    "    print(f\"‚úÖ Content-Based model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f98f198-7b45-4edf-9c8b-d9cca9cf3c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.460606Z",
     "iopub.status.busy": "2024-12-07T13:02:27.460318Z",
     "iopub.status.idle": "2024-12-07T13:02:27.475727Z",
     "shell.execute_reply": "2024-12-07T13:02:27.475272Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.460589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_collaborative_memory(train_df, save_path=\"../models/collaborative_memory_model.onnx\"):\n",
    "    \"\"\"\n",
    "    üöÄ Train and save the Collaborative Memory-Based Model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training data containing ['userId', 'jokeId', 'rating'].\n",
    "        save_path (str): Path where the model will be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Collaborative Memory-Based Model...\")\n",
    "\n",
    "    # Step 1: Initialize the model\n",
    "    print(\"‚öôÔ∏è Initializing the Collaborative Memory-Based Model...\")\n",
    "    memory_model = CollaborativeMemoryModel()\n",
    "    \n",
    "    # Step 2: Train the model\n",
    "    print(\"üöÄ Training Collaborative Memory-Based Model...\")\n",
    "    memory_model.train(train_df)\n",
    "    print(\"‚úÖ Collaborative Memory-Based Model trained successfully.\")\n",
    "    \n",
    "    # Step 3: Save the trained model\n",
    "    print(f\"üíæ Saving Collaborative Memory-Based model to {save_path}...\")\n",
    "    memory_model.save_model(save_path)\n",
    "    print(f\"‚úÖ Collaborative Memory-Based model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9fd411-5f21-4eb1-a05a-9fbaf51c282c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.476487Z",
     "iopub.status.busy": "2024-12-07T13:02:27.476226Z",
     "iopub.status.idle": "2024-12-07T13:02:27.497626Z",
     "shell.execute_reply": "2024-12-07T13:02:27.497175Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.476471Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_collaborative_model_based(train_df, save_path=\"../models/collaborative_model_based.npz\"):\n",
    "    \"\"\"\n",
    "    üöÄ Train and save the Collaborative Model-Based Model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training data containing ['userId', 'jokeId', 'rating'].\n",
    "        save_path (str): Path where the model will be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Collaborative Model-Based Model...\")\n",
    "\n",
    "    # Step 1: Initialize the model\n",
    "    print(\"‚öôÔ∏è Initializing the Collaborative Model-Based Recommender...\")\n",
    "    model_based = CollaborativeModelBased(factors=64, iterations=20, regularization=0.1)\n",
    "    \n",
    "    # Step 2: Train the model\n",
    "    print(\"üöÄ Training Collaborative Filtering Model...\")\n",
    "    model_based.train(train_df)\n",
    "    print(\"‚úÖ Collaborative Filtering Model trained successfully.\")\n",
    "    \n",
    "    # Step 3: Save the trained model\n",
    "    print(f\"üíæ Saving Collaborative Model-Based model to {save_path}...\")\n",
    "    model_based.save_model(save_path)\n",
    "    print(f\"‚úÖ Collaborative Model-Based model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb22352-d916-4629-8877-f4fdd5379e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.498415Z",
     "iopub.status.busy": "2024-12-07T13:02:27.498157Z",
     "iopub.status.idle": "2024-12-07T13:02:27.534318Z",
     "shell.execute_reply": "2024-12-07T13:02:27.533898Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.498399Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_session_based(train_df, \n",
    "                                 gru_path=\"../models/session_gru.pth\", \n",
    "                                 cooccurrence_path=\"../models/session_cooccurrence.npy\"):\n",
    "    \"\"\"\n",
    "    Train and save the Session-Based Model.\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Training Session-Based Model...\")\n",
    "\n",
    "    # Initialize the model\n",
    "    session_model = SessionBasedModel()\n",
    "    \n",
    "    # Train the model (includes both GRU and co-occurrence)\n",
    "    session_model.train(train_df)\n",
    "    \n",
    "    # Save the trained model\n",
    "    session_model.save_model(model_path=gru_path, co_occurrence_path=cooccurrence_path)\n",
    "    \n",
    "    print(f\"‚úÖ Session-Based model (GRU + Co-occurrence) saved at {gru_path} and {cooccurrence_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df9b00-e2c9-4178-a113-c04d00beefb2",
   "metadata": {},
   "source": [
    "### Load the training and joke data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f6bc0c-c46c-4ccb-8562-ddcd775dda6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:27.535082Z",
     "iopub.status.busy": "2024-12-07T13:02:27.534849Z",
     "iopub.status.idle": "2024-12-07T13:02:28.326625Z",
     "shell.execute_reply": "2024-12-07T13:02:28.325972Z",
     "shell.execute_reply.started": "2024-12-07T13:02:27.535066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading training data from ../data/processed/train_data.csv...\n",
      "‚úÖ Training data loaded successfully! Shape: (323433, 3)\n",
      "üìÇ Loading joke data from ../data/processed/jokes_with_clusters.parquet...\n",
      "‚úÖ Joke data loaded successfully! Shape: (150, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df, jokes_df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90c092-a525-4753-98a8-e5706c5218dc",
   "metadata": {},
   "source": [
    "### Train and Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af06ca5d-6597-41cd-b28a-4fa09e423684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:28.327851Z",
     "iopub.status.busy": "2024-12-07T13:02:28.327561Z",
     "iopub.status.idle": "2024-12-07T13:02:28.599669Z",
     "shell.execute_reply": "2024-12-07T13:02:28.598964Z",
     "shell.execute_reply.started": "2024-12-07T13:02:28.327832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training Baseline Model...\n",
      "üöÄ Training Baseline Model...\n",
      "üìä Filtered valid users for training...\n",
      "‚úÖ Top 100 Jokes calculated successfully. Total jokes: 100\n",
      "‚úÖ Baseline Model training completed!\n",
      "üíæ Saving model to ../models/baseline_model.parquet...\n",
      "‚úÖ Model saved successfully at ../models/baseline_model.parquet\n",
      "üíæ Baseline Model saved successfully at ../models/baseline_model.parquet\n"
     ]
    }
   ],
   "source": [
    "train_and_save_baseline(train_df, jokes_df, save_path=\"../models/baseline_model.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2ed6ed-c3cf-4643-bb7e-145d86a0b1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:28.601602Z",
     "iopub.status.busy": "2024-12-07T13:02:28.601214Z",
     "iopub.status.idle": "2024-12-07T13:02:28.887761Z",
     "shell.execute_reply": "2024-12-07T13:02:28.887108Z",
     "shell.execute_reply.started": "2024-12-07T13:02:28.601578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Content-Based Model...\n",
      "üì¶ Loaded 150 jokes and their embeddings of shape (150, 384).\n",
      "üöÄ Training Content-Based Recommender...\n",
      "üîç Calculating cosine similarity matrix...\n",
      "‚úÖ Cosine similarity matrix shape: (150, 150)\n",
      "‚úÖ Content-Based model trained successfully.\n",
      "üíæ Saving Content-Based model to ../models/content_based...\n",
      "‚úÖ Model saved at ../models/content_based\n",
      "‚úÖ Content-Based model saved successfully at ../models/content_based\n"
     ]
    }
   ],
   "source": [
    "train_and_save_content_based(jokes_df, save_path=\"../models/content_based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca77abf-933f-4f0d-83e7-76756924dce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:28.888823Z",
     "iopub.status.busy": "2024-12-07T13:02:28.888529Z",
     "iopub.status.idle": "2024-12-07T13:02:42.127160Z",
     "shell.execute_reply": "2024-12-07T13:02:42.126329Z",
     "shell.execute_reply.started": "2024-12-07T13:02:28.888804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Collaborative Memory-Based Model...\n",
      "‚öôÔ∏è Initializing the Collaborative Memory-Based Model...\n",
      "üöÄ Training Collaborative Memory-Based Model...\n",
      "üîπ Extracting user and item indices...\n",
      "üîπ Converting userId and jokeId to categorical indices...\n",
      "üîπ Creating the sparse ratings matrix...\n",
      "üîπ Calculating user-user similarity matrix...\n",
      "‚úÖ Similarity matrix of shape (13095, 13095) calculated successfully.\n",
      "‚úÖ Collaborative Memory-Based Model trained successfully.\n",
      "üíæ Saving Collaborative Memory-Based model to ../models/collaborative_memory_model.pkl...\n",
      "üíæ Saving CollaborativeMemoryModel to ../models/collaborative_memory_model.pkl...\n",
      "‚úÖ Collaborative Memory-Based model saved successfully at ../models/collaborative_memory_model.pkl\n",
      "‚úÖ Collaborative Memory-Based model saved successfully at ../models/collaborative_memory_model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_and_save_collaborative_memory(train_df, save_path=\"../models/collaborative_memory_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f92796-173d-4bce-a586-f92e0974cdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:42.128350Z",
     "iopub.status.busy": "2024-12-07T13:02:42.128031Z",
     "iopub.status.idle": "2024-12-07T13:02:49.569227Z",
     "shell.execute_reply": "2024-12-07T13:02:49.568653Z",
     "shell.execute_reply.started": "2024-12-07T13:02:42.128329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Collaborative Model-Based Model...\n",
      "‚öôÔ∏è Initializing the Collaborative Model-Based Recommender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 28 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training Collaborative Filtering Model...\n",
      "üîπ Starting training for Collaborative Filtering Model...\n",
      "üìà Training ALS model with 13095 users and 133 items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:06<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete!\n",
      "‚úÖ Collaborative Filtering Model trained successfully.\n",
      "üíæ Saving Collaborative Model-Based model to ../models/collaborative_model_based.npz...\n",
      "‚úÖ Model saved at ../models/collaborative_model_based.npz\n",
      "‚úÖ Collaborative Model-Based model saved successfully at ../models/collaborative_model_based.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_save_collaborative_model_based(train_df, save_path=\"../models/collaborative_model_based.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d681d90a-baa3-47be-8491-07d0375d622e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T13:02:49.570329Z",
     "iopub.status.busy": "2024-12-07T13:02:49.569961Z",
     "iopub.status.idle": "2024-12-07T13:08:55.608180Z",
     "shell.execute_reply": "2024-12-07T13:08:55.607481Z",
     "shell.execute_reply.started": "2024-12-07T13:02:49.570311Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training Session-Based Model...\n",
      "\n",
      "üîπ Extracting user sessions for GRU training...\n",
      "üîπ Extracting sessions from training data...\n",
      "‚úÖ Extracted 13095 sessions from training data.\n",
      "üì¶ Extracted 13095 sessions for training.\n",
      "üöÄ Training GRU4Rec with 151 items...\n",
      "üßÆ Epoch 1/5, Loss: 17854.6833\n",
      "üßÆ Epoch 2/5, Loss: 13653.0654\n",
      "üßÆ Epoch 3/5, Loss: 11768.9861\n",
      "üßÆ Epoch 4/5, Loss: 10441.6738\n",
      "üßÆ Epoch 5/5, Loss: 9777.4353\n",
      "‚úÖ GRU4Rec model training complete.\n",
      "‚úÖ GRU4Rec model saved at ../models/session_gru.pth\n",
      "‚ö†Ô∏è No co-occurrence matrix to save.\n",
      "‚úÖ Session-Based model (GRU + Co-occurrence) saved at ../models/session_gru.pth and ../models/session_cooccurrence.npy\n"
     ]
    }
   ],
   "source": [
    "train_and_save_session_based(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ac309-3edd-4316-b126-ebe445f4b900",
   "metadata": {},
   "source": [
    "__üìò Note on High Loss Values__\n",
    ">The high loss values observed during training are due to the absence of a timestamp column in the dataset. Without timestamps, the natural order of user interactions is unknown, leading to randomly ordered sessions. This disrupts the sequential nature of GRU-based models like GRU4Rec, causing the model to predict on incorrect targets, which inflates the loss values. A potential solution is to introduce synthetic timestamps or sort user interactions logically to preserve the session‚Äôs temporal structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
