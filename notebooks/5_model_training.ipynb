{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a592de-b12c-4a65-a9c0-7410d52d3da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:17.918300Z",
     "iopub.status.busy": "2024-12-08T09:16:17.917847Z",
     "iopub.status.idle": "2024-12-08T09:16:19.222059Z",
     "shell.execute_reply": "2024-12-08T09:16:19.221079Z",
     "shell.execute_reply.started": "2024-12-08T09:16:17.918272Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import json\n",
    "import inspect\n",
    "\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..')) \n",
    "sys.path.append(project_root)\n",
    "\n",
    "from models.baseline_model import BaselineModel\n",
    "from models.content_based_model import ContentBasedModel\n",
    "from models.collaborative_memory_model import CollaborativeMemoryModel\n",
    "from models.collaborative_model_based import CollaborativeModelBased\n",
    "from models.session_based_model import SessionBasedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7db87f-562a-4246-8200-2256f3c92157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.224094Z",
     "iopub.status.busy": "2024-12-08T09:16:19.223511Z",
     "iopub.status.idle": "2024-12-08T09:16:19.243875Z",
     "shell.execute_reply": "2024-12-08T09:16:19.243093Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.224072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(train_path=\"../data/processed/train_features.parquet\", jokes_path=\"../data/processed/jokes_with_clusters.parquet\"):\n",
    "    \"\"\"\n",
    "    Load training data and joke metadata.\n",
    "\n",
    "    Args:\n",
    "        train_path (str): Path to training data.\n",
    "        jokes_path (str): Path to joke metadata with clusters.\n",
    "\n",
    "    Returns:\n",
    "        train_df (pl.DataFrame): Training set.\n",
    "        jokes_df (pl.DataFrame): Jokes metadata.\n",
    "    \"\"\"\n",
    "    print(f\"üìÇ Loading training data from {train_path}...\")\n",
    "    train_df = pl.read_parquet(train_path)\n",
    "    print(f\"‚úÖ Training data loaded successfully! Shape: {train_df.shape}\")\n",
    "    \n",
    "    print(f\"üìÇ Loading joke data from {jokes_path}...\")\n",
    "    jokes_df = pl.read_parquet(jokes_path)\n",
    "    print(f\"‚úÖ Joke data loaded successfully! Shape: {jokes_df.shape}\")\n",
    "    \n",
    "    return train_df, jokes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc226fe0-2bc2-482a-87cb-bbe5aff9f522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.245111Z",
     "iopub.status.busy": "2024-12-08T09:16:19.244704Z",
     "iopub.status.idle": "2024-12-08T09:16:19.259231Z",
     "shell.execute_reply": "2024-12-08T09:16:19.258483Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.245091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_baseline(train_df: pl.DataFrame, items_df: pl.DataFrame, save_path: str = \"../models/baseline_model.parquet\"):\n",
    "    \"\"\"\n",
    "    Trains the BaselineModel and saves it as a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        train_df (pl.DataFrame): The training data containing 'userId', 'jokeId', 'rating', and other columns.\n",
    "        items_df (pl.DataFrame): The joke metadata containing at least the 'jokeId' column.\n",
    "        save_path (str): The path where the trained model should be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Training Baseline Model...\")\n",
    "\n",
    "    baseline_model = BaselineModel(ratings=train_df, items=items_df)\n",
    "    baseline_model.train()\n",
    "    print(\"‚úÖ Baseline Model training completed!\")\n",
    "\n",
    "    baseline_model.save_model(save_path)\n",
    "    print(f\"üíæ Baseline Model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90711d9-7b07-4482-bd7a-8d41ba0bd5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.261261Z",
     "iopub.status.busy": "2024-12-08T09:16:19.260900Z",
     "iopub.status.idle": "2024-12-08T09:16:19.286605Z",
     "shell.execute_reply": "2024-12-08T09:16:19.285874Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.261243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_content_based(jokes_df: pl.DataFrame, save_path: str = \"../models/content_based_model.pkl\"):\n",
    "    \"\"\"\n",
    "    üöÄ Trains the Content-Based Model and saves it as a single .pkl file.\n",
    "\n",
    "    Args:\n",
    "        jokes_df (pl.DataFrame): The joke features DataFrame, containing 'jokeId', 'embeddings', and other features.\n",
    "        save_path (str): The path where the trained model file will be saved (should end with .pkl).\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Content-Based Model...\")\n",
    "\n",
    "    # Extract joke IDs and embeddings from the DataFrame\n",
    "    print(\"üìã Extracting joke IDs and embeddings from the DataFrame...\")\n",
    "    joke_ids = jokes_df[\"jokeId\"].to_list()\n",
    "    embeddings = np.vstack(jokes_df[\"embeddings\"].to_list())\n",
    "\n",
    "    if embeddings.shape[0] != len(joke_ids):\n",
    "        raise ValueError(f\"‚ùå Number of embeddings ({embeddings.shape[0]}) does not match number of joke IDs ({len(joke_ids)}).\")\n",
    "    \n",
    "    print(f\"üì¶ Loaded {len(joke_ids)} jokes and their embeddings of shape {embeddings.shape}.\")\n",
    "\n",
    "    # Step 1: Train the Content-Based Recommender Model\n",
    "    print(\"üöÄ Training Content-Based Recommender...\")\n",
    "    content_model = ContentBasedModel()\n",
    "    content_model.train(embeddings, joke_ids)\n",
    "    print(f\"‚úÖ Content-Based model trained successfully.\")\n",
    "\n",
    "    # Step 2: Save the trained model\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üíæ Saving Content-Based model to {save_path}...\")\n",
    "    content_model.save_model(filepath=save_path)\n",
    "    print(f\"‚úÖ Content-Based model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f98f198-7b45-4edf-9c8b-d9cca9cf3c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.287759Z",
     "iopub.status.busy": "2024-12-08T09:16:19.287357Z",
     "iopub.status.idle": "2024-12-08T09:16:19.308778Z",
     "shell.execute_reply": "2024-12-08T09:16:19.308064Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.287740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_collaborative_memory(train_df, save_path=\"../models/collaborative_memory_model.pkl\"):\n",
    "    \"\"\"\n",
    "    üöÄ Train and save the Collaborative Memory-Based Model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training data containing ['userId', 'jokeId', 'rating'].\n",
    "        save_path (str): Path where the model will be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Collaborative Memory-Based Model...\")\n",
    "\n",
    "    # Step 1: Initialize the model\n",
    "    print(\"‚öôÔ∏è Initializing the Collaborative Memory-Based Model...\")\n",
    "    memory_model = CollaborativeMemoryModel()\n",
    "    \n",
    "    # Step 2: Train the model\n",
    "    print(\"üöÄ Training Collaborative Memory-Based Model...\")\n",
    "    memory_model.train(train_df)\n",
    "    print(\"‚úÖ Collaborative Memory-Based Model trained successfully.\")\n",
    "    \n",
    "    # Step 3: Save the trained model\n",
    "    print(f\"üíæ Saving Collaborative Memory-Based model to {save_path}...\")\n",
    "    memory_model.save_model(save_path)\n",
    "    print(f\"‚úÖ Collaborative Memory-Based model saved successfully at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9fd411-5f21-4eb1-a05a-9fbaf51c282c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.310008Z",
     "iopub.status.busy": "2024-12-08T09:16:19.309626Z",
     "iopub.status.idle": "2024-12-08T09:16:19.323770Z",
     "shell.execute_reply": "2024-12-08T09:16:19.323076Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.309989Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_collaborative_model_based(train_df: pl.DataFrame, save_path=\"../models/collaborative_model_based/\"):\n",
    "    \"\"\"\n",
    "    Train and save the Collaborative Model-Based Model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training data containing ['userId', 'jokeId', 'rating'].\n",
    "        save_path (str): Path where the model will be saved.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîπ Training Collaborative Model-Based Model...\")\n",
    "\n",
    "    # Step 1: Initialize the model\n",
    "    model_based = CollaborativeModelBased(factors=64, iterations=20, regularization=0.1)\n",
    "    \n",
    "    # Step 2: Train the model\n",
    "    model_based.train(train_df)\n",
    "    \n",
    "    # Step 3: Save the trained model\n",
    "    model_based.save_model(path=save_path)\n",
    "    \n",
    "    print(f\"‚úÖ Collaborative Model-Based model saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb22352-d916-4629-8877-f4fdd5379e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.324990Z",
     "iopub.status.busy": "2024-12-08T09:16:19.324575Z",
     "iopub.status.idle": "2024-12-08T09:16:19.345841Z",
     "shell.execute_reply": "2024-12-08T09:16:19.345092Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.324970Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_session_based(train_df, \n",
    "                                 gru_path=\"../models/session_gru.pth\", \n",
    "                                 cooccurrence_path=\"../models/session_cooccurrence.npy\",\n",
    "                                 metadata_path=\"../models/session_metadata.json\"):\n",
    "    \"\"\"\n",
    "    üöÄ Train and save the Session-Based Model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training data containing ['userId', 'jokeId'].\n",
    "        gru_path (str): Path to save the GRU model (.pth file).\n",
    "        cooccurrence_path (str): Path to save the co-occurrence matrix (.npy file).\n",
    "        metadata_path (str): Path to save the metadata (.json file).\n",
    "    \"\"\"\n",
    "    print(\"\\nüöÄ Training Session-Based Model...\")\n",
    "\n",
    "    # Step 1: Ensure directories exist\n",
    "    os.makedirs(os.path.dirname(gru_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(cooccurrence_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(metadata_path), exist_ok=True)\n",
    "    \n",
    "    # Step 2: Initialize the model\n",
    "    session_model = SessionBasedModel()\n",
    "    \n",
    "    # Step 3: Train the model (includes both GRU and co-occurrence)\n",
    "    session_model.train(train_df)\n",
    "    \n",
    "    # Step 4: Save the trained model and co-occurrence matrix\n",
    "    session_model.save_model(model_path=gru_path, co_occurrence_path=cooccurrence_path)\n",
    "    \n",
    "    # Step 5: Save metadata (if needed)\n",
    "    metadata = {\n",
    "        \"num_items\": session_model.model.output_layer.out_features if session_model.model else None,\n",
    "        \"embedding_dim\": session_model.model.embedding.embedding_dim if session_model.model else None,\n",
    "        \"hidden_dim\": session_model.model.gru.hidden_size if session_model.model else None\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    print(f\"‚úÖ Session-Based model (GRU + Co-occurrence) saved at {gru_path}, {cooccurrence_path}, and {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df9b00-e2c9-4178-a113-c04d00beefb2",
   "metadata": {},
   "source": [
    "### Load the training and joke data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f6bc0c-c46c-4ccb-8562-ddcd775dda6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.347321Z",
     "iopub.status.busy": "2024-12-08T09:16:19.346736Z",
     "iopub.status.idle": "2024-12-08T09:16:19.486653Z",
     "shell.execute_reply": "2024-12-08T09:16:19.485723Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.347301Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading training data from ../data/processed/train_features.parquet...\n",
      "‚úÖ Training data loaded successfully! Shape: (323433, 11)\n",
      "üìÇ Loading joke data from ../data/processed/jokes_with_clusters.parquet...\n",
      "‚úÖ Joke data loaded successfully! Shape: (150, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df, jokes_df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90c092-a525-4753-98a8-e5706c5218dc",
   "metadata": {},
   "source": [
    "### Train and Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af06ca5d-6597-41cd-b28a-4fa09e423684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.488043Z",
     "iopub.status.busy": "2024-12-08T09:16:19.487707Z",
     "iopub.status.idle": "2024-12-08T09:16:19.664648Z",
     "shell.execute_reply": "2024-12-08T09:16:19.663886Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.488020Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training Baseline Model...\n",
      "üöÄ Training Baseline Model...\n",
      "üìä Filtered valid users for training...\n",
      "‚úÖ All jokes ranked successfully. Total jokes: 133\n",
      "‚úÖ Baseline Model training completed!\n",
      "üíæ Saving Baseline Model to ../models/baseline_model/...\n",
      "‚úÖ Model saved successfully in ../models/baseline_model/\n",
      "üíæ Baseline Model saved successfully at ../models/baseline_model/\n"
     ]
    }
   ],
   "source": [
    "train_and_save_baseline(train_df, jokes_df, save_path=\"../models/baseline_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2ed6ed-c3cf-4643-bb7e-145d86a0b1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.667002Z",
     "iopub.status.busy": "2024-12-08T09:16:19.666671Z",
     "iopub.status.idle": "2024-12-08T09:16:19.712379Z",
     "shell.execute_reply": "2024-12-08T09:16:19.711619Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.666981Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Content-Based Model...\n",
      "üìã Extracting joke IDs and embeddings from the DataFrame...\n",
      "üì¶ Loaded 150 jokes and their embeddings of shape (150, 384).\n",
      "üöÄ Training Content-Based Recommender...\n",
      "üîç Calculating cosine similarity matrix...\n",
      "‚úÖ Cosine similarity matrix shape: (150, 150)\n",
      "‚úÖ Content-Based model trained successfully.\n",
      "üíæ Saving Content-Based model to ../models/content_based_model.pkl...\n",
      "‚úÖ Model saved successfully to ../models/content_based_model.pkl\n",
      "‚úÖ Content-Based model saved successfully at ../models/content_based_model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_and_save_content_based(jokes_df, save_path=\"../models/content_based_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca77abf-933f-4f0d-83e7-76756924dce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:19.713774Z",
     "iopub.status.busy": "2024-12-08T09:16:19.713306Z",
     "iopub.status.idle": "2024-12-08T09:16:32.472140Z",
     "shell.execute_reply": "2024-12-08T09:16:32.471176Z",
     "shell.execute_reply.started": "2024-12-08T09:16:19.713747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Collaborative Memory-Based Model...\n",
      "‚öôÔ∏è Initializing the Collaborative Memory-Based Model...\n",
      "üöÄ Training Collaborative Memory-Based Model...\n",
      "‚öôÔ∏è  Extracting user and item IDs...\n",
      "üì¶ Total users: 13095, Total items: 133\n",
      "‚öôÔ∏è  Converting userId and jokeId to categorical indices...\n",
      "üî¢ Building sparse matrix with shape (13095, 133)...\n",
      "‚úÖ Ratings matrix created with 323433 non-zero entries.\n",
      "üîπ Calculating user-user similarity matrix...\n",
      "‚úÖ Similarity matrix of shape (13095, 13095) calculated successfully.\n",
      "‚úÖ Collaborative Memory-Based Model trained successfully.\n",
      "üíæ Saving Collaborative Memory-Based model to ../models/collaborative_memory_model.pkl...\n",
      "üíæ Saving entire CollaborativeMemoryModel to ../models/collaborative_memory_model.pkl...\n",
      "‚úÖ Collaborative Memory-Based model saved successfully at ../models/collaborative_memory_model.pkl\n",
      "‚úÖ Collaborative Memory-Based model saved successfully at ../models/collaborative_memory_model.pkl\n"
     ]
    }
   ],
   "source": [
    "train_and_save_collaborative_memory(train_df, save_path=\"../models/collaborative_memory_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f92796-173d-4bce-a586-f92e0974cdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:32.473774Z",
     "iopub.status.busy": "2024-12-08T09:16:32.473437Z",
     "iopub.status.idle": "2024-12-08T09:16:39.944985Z",
     "shell.execute_reply": "2024-12-08T09:16:39.944074Z",
     "shell.execute_reply.started": "2024-12-08T09:16:32.473746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Training Collaborative Model-Based Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 28 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Starting training for Collaborative Filtering Model...\n",
      "üìà Training ALS model with 13095 users and 133 items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:07<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete!\n",
      "üíæ Saving model to ../models/collaborative_model_based/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully at ../models/collaborative_model_based/\n",
      "‚úÖ Collaborative Model-Based model saved at ../models/collaborative_model_based/\n"
     ]
    }
   ],
   "source": [
    "train_and_save_collaborative_model_based(train_df, save_path='../models/collaborative_model_based/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7a8fbfb-3c0c-47a7-88b5-0198e0a5eb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:39.946296Z",
     "iopub.status.busy": "2024-12-08T09:16:39.945919Z",
     "iopub.status.idle": "2024-12-08T09:18:44.415299Z",
     "shell.execute_reply": "2024-12-08T09:18:44.414406Z",
     "shell.execute_reply.started": "2024-12-08T09:16:39.946275Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Extracting user sessions for GRU training...\n",
      "üîπ Extracting logical sessions from training data...\n",
      "‚úÖ Extracted 13095 sessions from training data.\n",
      "üöÄ Training GRU4Rec with 133 items (total unique jokes) ...\n",
      "üßÆ Epoch 1/5, Loss: 16992.0939\n",
      "üßÆ Epoch 2/5, Loss: 14084.2317\n",
      "üßÆ Epoch 3/5, Loss: 12606.3266\n",
      "üßÆ Epoch 4/5, Loss: 11584.8043\n",
      "üßÆ Epoch 5/5, Loss: 10731.4044\n",
      "‚úÖ GRU4Rec model training complete.\n"
     ]
    }
   ],
   "source": [
    "session_model = SessionBasedModel()\n",
    "session_model.train(train_df, embedding_dim=64, hidden_dim=128, epochs=5, lr=0.001)\n",
    "session_model.save_model(folder_path=\"../models/session_based_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ac309-3edd-4316-b126-ebe445f4b900",
   "metadata": {},
   "source": [
    "__üìò Note on High Loss Values__\n",
    ">The high loss values observed during training are due to the absence of a timestamp column in the dataset. Without timestamps, the natural order of user interactions is unknown, leading to randomly ordered sessions. This disrupts the sequential nature of GRU-based models like GRU4Rec, causing the model to predict on incorrect targets, which inflates the loss values. A potential solution is to introduce synthetic timestamps or sort user interactions logically to preserve the session‚Äôs temporal structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
